# fastdl âš¡

A fast, minimal HTTP downloader written in **Rust**, supporting **parallel chunked downloads** via HTTP `Range` requests.

This project began as a learning exercise and evolved into a real, working download manager â€” focused on correctness, performance, and simplicity.

---

## âœ¨ Features

- ğŸš€ **Parallel downloads** using HTTP `Range` headers
- ğŸ“¦ Automatic fallback to single-stream download when ranges arenâ€™t supported
- ğŸ“Š Real-time progress bar with speed reporting
- ğŸ§  Smart use of `HEAD` requests to probe server capabilities
- ğŸ’¾ Constant-memory streaming (no full-file buffering)
- ğŸ›  Simple, readable codebase (no unsafe code)

---

## ğŸ“¦ How It Works

1. Sends an HTTP `HEAD` request to determine:
   - File size (`Content-Length`)
   - Whether the server supports byte ranges (`Accept-Ranges`)
2. Pre-allocates the output file to the full size
3. Chooses download strategy:
   - **Single stream** for small files or servers without range support
   - **Parallel chunked downloads** for large files with range support
4. Streams data directly to disk while updating a shared progress bar

Each chunk is downloaded independently and written to a fixed byte range in the output file â€” no locks, no overlaps.

---

## ğŸ–¥ Usage

### Build

```bash
cargo build --release
```

### Download a file (single stream)

```bash
fastdl -u https://example.com/file.iso
```

### Download with parallel chunks

```bash
fastdl -u https://example.com/file.iso -j 4
```

### Specify output file

```bash
fastdl -u https://example.com/file.iso -o myfile.iso
```

---

## ğŸ§ª Recommended Test Files

For reliable testing of parallel downloads:

- http://ipv4.download.thinkbroadband.com/1GB.zip

(Some CDNs throttle per-IP bandwidth, so not all servers show speedups with parallelism.)

---

## âš ï¸ Notes & Limitations

- HTTPS testing depends on system clock and certificate validity
- Parallel downloads may not improve speed on all servers
- Currently blocks on file I/O (uses `std::fs::File`)
- No resume support yet (see roadmap)

---

## ğŸ›£ Roadmap / Future Features

Planned improvements:

- â¯ Resume support (continue partially downloaded files)
- ğŸ” Per-chunk retry with exponential backoff
- ğŸ“ Adaptive chunk sizing based on file size
- ğŸ§¾ Filename detection via `Content-Disposition`
- ğŸ§µ Async file I/O using `tokio::fs`
- ğŸ” Optional checksum verification (SHA256)
- ğŸ§ª Benchmark mode for testing throughput
- ğŸŒ (Long-term) BitTorrent support

---

## ğŸ§  Why This Project Exists

This project was built to understand how real download managers work under the hood:

- HTTP semantics
- Streaming I/O
- Concurrency with correctness
- Real-world CDN behavior

It is intentionally minimal, readable, and dependency-light.

---

## ğŸ¦€ Built With

- Rust
- tokio
- reqwest
- clap
- indicatif
- anyhow

---

## ğŸ“œ License

MIT (or pick your preferred license).

---

## ğŸ™Œ Acknowledgements

Inspired by tools like wget, aria2, and curl, but built from scratch to learn how they actually work.

